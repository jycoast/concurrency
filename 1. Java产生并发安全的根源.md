

# 并发编程开篇语

## 为什么学习并发编程？

- 并发无处不在，是构建高性能应用的基础，是阅读开源代码的基础
- 企业面试的核心

## 并发编程有什么难点？

1. 并发编程涉及到计算机的知识面非常广，数据结构，计算机组成原理，内存、操作系统，JVM，CPU等都需要一定的了解；
2. 如果要了解底层的实现原理，必然要阅读一些C/C++代码，这对大部分Java程序员也是不友好的；
3. 在缺乏知识体系的情况下，很多概念理解起来会非常抽象和难以理解，例如 happen-before；
4. 对JSR的不了解，导致不理解有些概念是怎么来的，例如volatile关键字的作用；
5. 网上的资料虽然很多，但缺少从全局的角度介绍某些概念的来源。例如，Java 里 synchronized、wait()/notify() 相关的知识很琐碎，看懂难，会用更难。但实际上 synchronized、wait()、notify() 不过是操作系统领域里管程模型的一种实现而已，Java SDK 并发包里的条件变量 Condition 也是管程里的概念，synchronized、wait()/notify()、条件变量这些知识如果单独理解，自然是管中窥豹。但是如果站在管程这个理论模型的高度，你就会发现这些知识原来这么简单，同时用起来也就得心应手了。

## 如何学习并发编程？

跳出来，看全景，钻进去，看本质。

学习最忌讳的就是“盲人摸象”，只看到局部，而没有看到全局。所以，需要从一个个单一的知识和技术中“跳出来”，高屋建瓴地看并发编程。当然，这首要之事就是你建立起一张全景图。

但是光跳出来还不够，还需要下一步，就是在某个问题上钻进去，深入理解，找到本质。对知识点不是浅尝辄止，知其然知其所以然，才算真的学明白了。

## 并发编程的核心问题

并发编程领域可以抽象成三个核心问题：分工、同步和互斥。

分工指的是：将大的问题拆分成互不相干的子问题。

同步指的是：线程与线程之间存在依赖关系。

互斥指的是：对共享资源访问的顺序。

你会发现所有并发编程中的概念、关键字、工具类都是围绕这三个方面展开的。

## 并发编程分享内容

- 产生线程安全问题的根源是什么？
- Java语言是如何解决线程安全问题的？
- Jvm是如何解决线程安全问题的？
- 并发、线程与等待通知机制
- Jvm管程实现探究
- Java语言管程实现探究
- 从管程的实现看透并发编程的本质
- Juc包下的工具类和并发容器
- 线程池与阻塞队列
- final关键字
- 从操作系统层面理解Java中的线程
- 分布式锁如何实现？
- MySQL是如何处理并发问题的?
- Redis是如何处理并发问题的？
- 并发编程中的设计模式

# 什么是线程安全问题

产生线程安全的例子：

```java
public class VisibilityTest {

    private boolean flag = true;

    private int count = 0;

    public void refresh() {
        flag = false;
        System.out.println(Thread.currentThread().getName() + "修改flag为false");
    }

    public void load() {
        while (flag) {
            count++;
        }
        System.out.println(Thread.currentThread().getName() + "跳出循环：count=" + count);
    }

    public static void main(String[] args) throws InterruptedException {
        VisibilityTest test = new VisibilityTest();

        Thread threadA = new Thread(() -> test.load(), "threadA");
        threadA.start();

        Thread.sleep(1000);

        Thread threadB = new Thread(() -> test.refresh(), "threadB");
        threadB.start();
    }
}
```

# 并发三大特性

要理解产生这个问题的原因，我们就需要对并发三大特性有所了解。

并发三大特性指的是：可见性、有序性、原子性。

## 可见性

在单核时代，所有的线程都是在一颗 CPU 上执行，CPU 缓存与内存的数据一致性容易解决。因为所有线程都是操作同一个 CPU 的缓存，一个线程对缓存的写，对另外一个线程来说一定是可见的。例如在下面的图中，线程 A 和线程 B 都是操作同一个 CPU 里面的缓存，所以线程 A 更新了变量 V 的值，那么线程 B 之后再访问变量 V，得到的一定是 V 的最新值（线程 A 写过的值）。

<img src="https://blog-1304855543.cos.ap-guangzhou.myqcloud.com/blog/image-20250422113415754.png" alt="image-20250422113415754" style="zoom: 67%;" />

一个线程对共享变量的修改，另外一个线程能够立刻看到，我们称为**可见性**。

多核时代，每颗 CPU 都有自己的缓存，这时 CPU 缓存与内存的数据一致性就没那么容易解决了，当多个线程在不同的 CPU 上执行时，这些线程操作的是不同的 CPU 缓存。比如下图中，线程 A 操作的是 CPU-1 上的缓存，而线程 B 操作的是 CPU-2 上的缓存，很明显，这个时候线程 A 对变量 V 的操作对于线程 B 而言就不具备可见性了。这个就属于硬件程序员给软件程序员挖的“坑”。

<img src="https://blog-1304855543.cos.ap-guangzhou.myqcloud.com/blog/image-20250422113457989.png" alt="image-20250422113457989" style="zoom:67%;" />

## 原子性

由于 IO 太慢，早期的操作系统就发明了多进程，即便在单核的 CPU 上我们也可以一边听着歌，一边写 Bug，这个就是多进程的功劳。

操作系统允许某个进程执行一小段时间，例如 50 毫秒，过了 50 毫秒操作系统就会重新选择一个进程来执行（我们称为“任务切换”），这个 50 毫秒称为“**时间片**”。

<img src="https://blog-1304855543.cos.ap-guangzhou.myqcloud.com/blog/image-20250422113553926.png" alt="image-20250422113553926" style="zoom:67%;" />

在一个时间片内，如果一个进程进行一个 IO 操作，例如读个文件，这个时候该进程可以把自己标记为“休眠状态”并出让 CPU 的使用权，待文件读进内存，操作系统会把这个休眠的进程唤醒，唤醒后的进程就有机会重新获得 CPU 的使用权了。

这里的进程在等待 IO 时之所以会释放 CPU 使用权，是为了让 CPU 在这段等待时间里可以做别的事情，这样一来 CPU 的使用率就上来了；此外，如果这时有另外一个进程也读文件，读文件的操作就会排队，磁盘驱动在完成一个进程的读操作后，发现有排队的任务，就会立即启动下一个读操作，这样 IO 的使用率也上来了。

Java 并发程序都是基于多线程的，自然也会涉及到任务切换，任务切换的时机大多数是在时间片结束的时候，我们现在基本都使用高级语言编程，高级语言里一条语句往往需要多条 CPU 指令完成，例如上面代码中的count += 1，至少需要三条 CPU 指令。

指令 1：首先，需要把变量 count 从内存加载到 CPU 的寄存器；

指令 2：之后，在寄存器中执行 +1 操作；

指令 3：最后，将结果写入内存（缓存机制导致可能写入的是 CPU 缓存而不是内存）。

操作系统做任务切换，可以发生在任何一条 **CPU 指令**执行完，是的，是 CPU 指令，而不是高级语言里的一条语句。对于上面的三条指令来说，我们假设 count=0，如果线程 A 在指令 1 执行完后做线程切换，线程 A 和线程 B 按照下图的序列执行，那么我们会发现两个线程都执行了 count+=1 的操作，但是得到的结果不是我们期望的 2，而是 1。

<img src="https://blog-1304855543.cos.ap-guangzhou.myqcloud.com/blog/image-20250422113709088.png" alt="image-20250422113709088" style="zoom:67%;" />

我们潜意识里面觉得 count+=1 这个操作是一个不可分割的整体，就像一个原子一样，线程的切换可以发生在 count+=1 之前，也可以发生在 count+=1 之后，但就是不会发生在中间。**我们把一个或者多个操作在 CPU 执行的过程中不被中断的特性称为原子性**。CPU 能保证的原子操作是 CPU 指令级别的，而不是高级语言的操作符，这是违背我们直觉的地方。因此，很多时候我们需要在高级语言层面保证操作的原子性。

原子性的例子：

```java
public class AtomicityTest {

    private int count = 0;

    public void increment() {
        count++;
    }

    public int getCount() {
        return count;
    }

    public static void main(String[] args) throws InterruptedException {
        AtomicityTest counter = new AtomicityTest();
        Runnable task = () -> {
            for (int i = 0; i < 1000; i++) {
                counter.increment();
            }
        };

        Thread t1 = new Thread(task);
        Thread t2 = new Thread(task);
        t1.start();
        t2.start();

        // 等待两个线程执行完
        t1.join();
        t2.join();

        System.out.println("最终计数: " + counter.getCount()); // 期待输出 2000
    }
}
```

## 有序性

有序性指的是程序按照代码的先后顺序执行。编译器为了优化性能，有时候会改变程序中语句的先后顺序，例如程序中：“a=6；b=7；”编译器优化后可能变成“b=7；a=6；”，在这个例子中，编译器调整了语句的顺序，但是不影响程序的最终结果。不过有时候编译器及解释器的优化可能导致意想不到的 Bug。

```java
public class OrderingTest {
    
    // volatile 防止指令重排序
    private volatile static OrderingTest singleDcl = null;
    
    private static OrderingTest getInstance() {
        if (singleDcl == null) {
            synchronized (SingleDcl.class) {
                if (singleDcl == null) {
                    // 1.开辟内存空间
                    // 2.对象初始化
                    // 3.singleDcl指向内存空间的地址
                    singleDcl = new OrderingTest();
                }
            }
        }
        return singleDcl;
    }
}
```

**为什么会出现指令重排序？**

计算机在执行程序时，为了提高性能，编译器和处理器常常会对指令做重排。

**为什么指令重排序可以提高性能？**

简单地说，每一个指令都会包含多个步骤，每个步骤可能使用不同的硬件。因此，**流水线技术**产生了，它的原理是指令1还没有执行完，就可以开始执行指令2，而不用等到指令1执行结束之后再执行指令2，这样就大大提高了效率。

但是，流水线技术最害怕**中断**，恢复中断的代价是比较大的，所以我们要想尽办法不让流水线中断。指令重排就是减少中断的一种技术。

```java
a = b + c;
d = e - f ;
```

先加载b、c（**注意，即有可能先加载b，也有可能先加载c**），但是在执行add(b,c)的时候，需要等待b、c装载结束才能继续执行，也就是增加了停顿，那么后面的指令也会依次有停顿,这降低了计算机的执行效率。

为了减少这个停顿，我们可以先加载e和f,然后再去加载add(b,c),这样做对程序（串行）是没有影响的,但却减少了停顿。既然add(b,c)需要停顿，那还不如去做一些有意义的事情。

综上所述，**指令重排对于提高CPU处理性能十分必要。虽然由此带来了乱序的问题，但是这点牺牲是值得的。**

指令重排一般分为以下三种：

- **编译器优化重排**

  编译器在**不改变单线程程序语义**的前提下，可以重新安排语句的执行顺序。

- **指令并行重排**

  现代处理器采用了指令级并行技术来将多条指令重叠执行。如果**不存在数据依赖性**(即后一个执行的语句无需依赖前面执行的语句的结果)，处理器可以改变语句对应的机器指令的执行顺序。

- **内存系统重排**

  由于处理器使用缓存和读写缓存冲区，这使得加载(load)和存储(store)操作看上去可能是在乱序执行，因为三级缓存的存在，导致内存与缓存的数据同步存在时间差。

**指令重排可以保证串行语义一致，但是没有义务保证多线程间的语义也一致**。所以在多线程下，指令重排序可能会导致一些问题。

# 如何解决线程安全问题？

## Java 语言层面

- **原子性**：单个变量用 JUC 原子类（AtomicInteger、AtomicLong 等）；任意代码段用 synchronized 或 ReentrantLock。  
- **可见性**：volatile、synchronized、Lock、final、static 以及所有 JUC 并发工具均保证。  
- **有序性**：volatile、synchronized、Lock、final、static 均禁止编译器和处理器重排序。

## JVM 底层实现

- **原子性**：原子类依赖单指令 LOCK CMPXCHG（CAS），synchronized 依赖 monitorenter/monitorexit 结合偏向锁/轻量锁/重量锁。  
- **可见性**：写线程在 volatile 通过内存屏障失效本地缓存；synchronized 和 Lock 通过内存屏障，配合 MESI 协议+缓存锁/总线锁实现。  
- **有序性**：volatile 写插入 StoreLoad 屏障，volatile 读插入 LoadLoad + LoadStore 屏障，synchronized/Lock/final 插入全屏障，彻底阻止重排序。

## 开发者层面

- **happens-before**

**总结** 

Java 层通过关键字和 JUC 工具提供简洁接口

JVM 层通过内存屏障、LOCK 前缀指令和 MESI 缓存一致性协议真正保障原子性、可见性与有序性。

提供 happens-before 原则帮助开发者判断编写的程序是否有并发安全问题。

# CAS-解决并发编程的基石

## 什么是原子操作？

并发里的原子性和事务中的原子操作是完全一样的概念，假定有两个操作 A 和 B 都包含多个步骤，如果从执行 A 的线程来看， 当另一个线程执行 B 时， 要么将 B 全部执行完， 要么完全不执行 B ，执行 B 的线程看 A 的操作也是一样的， 那么 A 和 B 对彼此来说是原子的。

实现原子操作可以使用锁， 锁机制满足基本的需求是没有问题的了， 但是有的时候我们的需求并非这么简单，我们需要更有效，更加灵活的机制，synchronized 关键字是基于阻塞的锁机制，也就是说当一个线程拥有锁的时候， 访问同一资源的其它线程需要等待，直到该线程释放锁。

使用锁机制实现的原子性可能存在问题： 首先，如果被阻塞的线程优先级很高很重要怎么办？其次， 如果获得锁的线程一直不释放锁怎么办？ 同时，还有可能出现一些例如死锁之类的情况， 最后，其实锁机制是一种比较粗糙， 粒度比较大的机制， 相对于像计数器这样的需求有点儿过于笨重。这个时候就需要用到CAS机制。

**CAS**，**全称Compare And Swap（比较与交换）**， **CAS（V, A, B）**，**V为内存地址、A为预期原值，B为新值**。如果内存地址的值与预期原值相匹配，那么将该位置值更新为新值。否则，说明已经被其他线程更新，处理器不做任何操作；无论哪种情况，它都会在 CAS 指令之前返回该位置的值。而我们可以使用自旋，循环CAS，重新读取该变量再尝试再次修改该变量，也可以放弃操作。

<img src="https://blog-1304855543.cos.ap-guangzhou.myqcloud.com/blog/image-20251120220952594.png" alt="image-20251120220952594" style="zoom:67%;" />

## CAS实现原子操作的三大问题

### ABA 问题

CAS 在更新前会检查值是否被改动过，若未变则更新。但它只看“当前值”，不关心历史： 如果一个值从 A → B → 又变回 A，CAS 会误以为“没变过”，从而错误地认为可以安全更新，这就是 **ABA 问题**。

**解决方法**：给变量加一个递增的版本号（stamp）。 每次修改都同时更新版本号，序列就变成： 1A → 2B → 3A 即使值又回到 A，版本号不同，CAS 就能识别出中间被改过。

**通俗比喻**： 你桌上一杯水，走开一趟回来发现水还在，就直接喝了 —— 这就是典型的 ABA 问题（你以为没人动，其实被同事喝光又续满了一杯）。

而讲卫生的程序员会这样做： 放杯子时在旁边贴张纸条写上 “0”。 规定：谁动水就必须先把数字加 1。 你回来一看纸条上写着 “2”，哪怕水还是满的，你也知道：这杯水已经“脏”了，不能喝了。

Java 直接提供了这个机制：

- AtomicStampedReference<V>（值 + int 版本号）
- AtomicMarkableReference<V>（值 + boolean 标记位，简化版）

用它们实现 CAS，就彻底杜绝 ABA 问题。

### 循环时间长开销大

自旋 CAS 如果长时间不成功，会给 CPU 带来非常大的执行开销。

### 只能保证一个共享变量的原子操作

CAS 原生只能保证**单个共享变量**的原子性。

- 对单个变量，可通过循环 CAS（自旋）实现原子更新。
- 对多个共享变量，循环 CAS 无法保证整体原子性，此时需使用锁。
- 替代方案：将多个共享变量合并为一个对象，通过 AtomicReference<V> 对该对象整体进行 CAS，从而实现多变量的复合原子操作。

Java 1.5 引入的 AtomicReference 正是为此设计：把任意数量的变量封装进一个对象，用一次引用 CAS 完成“多字段”原子更新，巧妙规避了传统锁。

## JDK 中相关原子操作类的使用

以AtomicInteger为例：

 | 方法                                            | 功能描述                                      | 返回值含义                 |
  | ----------------------------------------------- | --------------------------------------------- | -------------------------- |
  | `int addAndGet(int delta)`                      | 原子地将 delta 加到当前值，返回**加后的结果** | 新值                       |
  | `int getAndAdd(int delta)`                      | 原子地将 delta 加到当前值，返回**加前的旧值** | 旧值                       |
  | `boolean compareAndSet(int expect, int update)` | 如果当前值 == expect，则原子更新为 update     | 是否更新成功（true/false） |
  | `int getAndIncrement()`                         | 原子自增（+1），返回**自增前的值**            | 旧值（等价于 i++）         |
  | `int incrementAndGet()`                         | 原子自增（+1），返回**自增后的值**            | 新值（等价于 ++i）         |
  | `int getAndSet(int newValue)`                   | 原子地将值设为 newValue，返回**设置前的旧值** | 旧值                       |


# CAS 实现机制深度解析

## 硬件原子指令实现CAS

> 不支持原子指令的硬件： - 早期的简单处理器（如 8086、某些 8 位微控制器）没有原生的原子指令。 一些低端嵌入式系统（如老式 AVR 或 PIC 微控制器）缺乏硬件支持。 某些特殊用途处理器可能故意省略复杂指令以简化设计。
>
> 现代处理器几乎都支持原子指令，因为多核和并发是标配。但在极低功耗或极简设计的场景中，硬件可能不提供。

### 主流架构的CAS实现

**x86/x86_64架构**

- 核心指令：`cmpxchg`（Compare and Exchange）
- 关键机制：`lock`前缀确保原子性
- 汇编示例：
  ```asm
  mov eax, [expected]     ; 加载期望值
  lock cmpxchg [ptr], desired ; 原子比较并交换
  setz al                 ; 设置操作结果标志
  ```
  *修正说明：原示例缺少`setz al`指令，需补充返回值设置*

**ARM架构**

- 指令对：`ldrex`和`strex`（Load-Exclusive/Store-Exclusive）
- 乐观锁机制：通过本地监视器检测并发冲突
  ```asm
  ldrex r1, [ptr]         ; 加载当前值并标记监视器
  cmp r1, expected        ; 比较值
  bne fail                ; 不相等则失败
  strex r2, desired, [ptr]; 尝试存储新值
  cmp r2, #0              ; 检查是否成功（0表示成功）
  beq success             ; 成功跳转
  fail:
  ```

**编译器支持**
- GCC/Clang等编译器通过`__atomic`内置函数生成架构优化指令
- 示例：`__atomic_compare_exchange_n`会映射到`cmpxchg`或`ldrex/strex`

### 硬件原子指令支持现状

| 架构         | 原子指令支持                     | 关键特性                     |
|--------------|----------------------------------|------------------------------|
| x86/x86_64   | `cmpxchg`, `lock`前缀          | 支持字节/字/双字/四字操作    |
| ARMv6+       | `ldrex`/`strex`                 | 需配合内存屏障使用           |
| RISC-V       | AMO指令（A扩展）                | 支持原子加减/逻辑运算        |
| PowerPC      | `lwarx`/`stwcx.`                | 需配合`cmp`指令完成CAS逻辑   |

### 硬件原子性实现关键技术

三大核心技术：原子指令集、缓存一致性协议、内存屏障。

**原子指令集**

- x86的`LOCK`前缀会：
  - 锁定总线直至指令完成
  - 阻塞其他核心的缓存访问
- ARM的`ldrex`/`strex`通过本地监视器实现：
  - 加载时标记缓存行独占
  - 存储时验证独占状态

**缓存一致性协议（MESI）**

当CPU执行原子操作（如`LOCK CMPXCHG`）时，MESI协议会将目标缓存行状态从`Shared(S)`提升至`Exclusive(E)`或`Modified(M)`，此时其他核心的相同缓存行会被标记为`Invalid(I)`，形成**硬件级互斥锁**

**内存屏障（Memory Barrier）**

强制原子写操作结果对其他核可见，保证原子读操作后的加载顺序，阻止所有指令重排序。

## 硬件没有原子指令实现CAS

| 平台/时代                                 | 实现方式                                                     | 原理/代价                                                    |
| ----------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 早期 x86（386/486 无 CMPXCHG）            | 用 `XCHG` 指令（隐含 LOCK）或 `.byte 0xF0,0x0F,0xB0,...` 强制总线锁 | XCHG 本身总是带 LOCK，拿它模拟 CAS，但逻辑复杂、性能差       |
| 单核或无 SMP 的机器                       | 直接关闭中断（CLI/STI）                                      | 最简单：禁止中断 = 禁止抢占 = 单线程串行执行 → 天然原子，但不支持多核 |
| 早期 PowerPC、MIPS、SPARC                 | LL/SC（Load-Linked / Store-Conditional）序列 + 总线仲裁      | 硬件虽提供 LL/SC，但若无 CAS，内核用总线锁或全局自旋锁包装成 CAS 接口 |
| 所有没有硬件 CAS 的多核系统（最通用做法） | **操作系统提供的原子原语**（内核态总线锁）                   | 用户态调用系统调用（如 Linux 的 `futex`、`cmpxchg` 模拟）或 `rt_mutex`，内核用总线锁或大内核锁（Big Kernel Lock）实现真正原子性 |

## Java中的CAS实现

### Java层（Unsafe）

jdk/src/share/classes/sun/misc/Unsafe.java

### JVM native实现（HotSpot）

查看链接：https://hg.openjdk.org/jdk8/jdk8/hotspot/file/87ee5ee27509/src/share/vm/prims/unsafe.cpp

搜索：CompareAndSwapLong

核心代码：

```c++
Atomic::cmpxchg(x, addr, e)
```

### 真正汇编实现（CPU相关）

查看链接：https://hg.openjdk.org/jdk8/jdk8/hotspot/file/87ee5ee27509/src/cpu/x86/vm/x86_64.ad

搜索：CompareAndSwapL

实现代码：

```cpp
instruct compareAndSwapL(rRegI res,
                         memory mem_ptr,
                         rax_RegL oldval, rRegL newval,
                         rFlagsReg cr)
%{
  predicate(VM_Version::supports_cx8());
  match(Set res (CompareAndSwapL mem_ptr (Binary oldval newval)));
  effect(KILL cr, KILL oldval);

  format %{ "cmpxchgq $mem_ptr,$newval\t# "
            "If rax == $mem_ptr then store $newval into $mem_ptr\n\t"
            "sete    $res\n\t"
            "movzbl  $res, $res" %}
  opcode(0x0F, 0xB1);
  ins_encode(lock_prefix,
             REX_reg_mem_wide(newval, mem_ptr),
             OpcP, OpcS,
             reg_mem(newval, mem_ptr),
             REX_breg(res), Opcode(0x0F), Opcode(0x94), reg(res), // sete
             REX_reg_breg(res, res), // movzbl
             Opcode(0xF), Opcode(0xB6), reg_reg(res, res));
  ins_pipe( pipe_cmpxchg );
%}
```

解释：

```asm
instruct compareAndSwapL(
    rRegI res,          // 返回值：1 表示成功，0 表示失败（boolean）
    memory mem_ptr,     // 要操作的内存地址
    rax_RegL oldval,    // 预期值，必须预先放在 RAX 寄存器（x86 cmpxchg 硬件要求）
    rRegL newval,       // 要写入的新值
    rFlagsReg cr        // 影响 ZF 标志位，用于判断是否成功
)
```

predicate(VM_Version::supports_cx8()); 只有 CPU 支持 CMPXCHG8B（即支持 64 位原子操作）才启用此指令。

对应 Java 中 Unsafe.compareAndSwapLong 返回 boolean 的版本：

```asm
match(Set res (CompareAndSwapL mem_ptr (Binary oldval newval)));
```

**生成的真实汇编**（核心就两行）：

```asm
LOCK CMPXCHGQ [mem_ptr], newval     ; 原子比较并交换
SETE al                              ; 如果相等（成功），把 1 写入 al
MOVZBL res, al                       ; 把 al 零扩展到 32 位返回
```

必须 LOCK 前缀 → 保证多核原子性

**成功时**：ZF=1，内存被写入 newval，RAX 仍为 oldval。

**失败时**：ZF=0，RAX 被更新为内存当前实际值（这就是为什么 CAS 失败后要重试时直接用 RAX 里的值）。

最后用 SETE + MOVZBL 把成功/失败转成 0/1 返回给 Java。

> **LOCK 前缀 = 告诉 CPU：“我要独占这 64 字节缓存行，别的核在我的指令完成前，一律不准碰它！”**
>
> ### 具体过程（现代 Intel/AMD CPU，2010 年以后）
>
> 1. 你执行一条带 LOCK 前缀的指令 例如：lock cmpxchg [addr], rax
> 2. 当前核立刻向总线发出 **RFO（Request For Ownership）** 请求 → 意思是“我要独占（Ownership）addr 所在的缓存行”
> 3. 所有其他核收到这个请求后，**强制把自己的同一缓存行设为 Invalid** → 哪怕它们正准备读或写，也必须立刻放弃
> 4. 当前核拿到独占权后，**只有它一个人**能修改这 64 字节 → 整个 cmpxchg 指令期间，没有任何其他核能干扰
> 5. 指令执行完后，当前核把新值写回，并解除独占 → 其他核重新可以访问
>
> 这整个过程由硬件（MESI 协议 + 总线仲裁）在几十纳秒内自动完成，**不需要操作系统、也不需要锁总线**，只锁一行缓存，所以极快。

# 参考链接

在线查看JDK源码：https://hg.openjdk.org/jdk8/jdk8/hotspot/file

JSR133：http://ifeve.com/wp-content/uploads/2014/03/JSR133%E4%B8%AD%E6%96%87%E7%89%88.pdf

# 思考题

volatile可以解决原子性的问题吗？